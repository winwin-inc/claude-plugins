#!/usr/bin/env bash
# å…ƒæ•°æ®è¿½è¸ªå‡½æ•°åº“
# ç‰ˆæœ¬: 3.1.0
# ç”¨æ³•: source plugins/libs/metadata_tracker.sh

# WIKI_CONFIG ç”±è°ƒç”¨æ–¹è®¾ç½®ï¼ˆé€šè¿‡ config_resolver.shï¼‰
if [ -z "$WIKI_CONFIG" ]; then
    # å¦‚æœæœªè®¾ç½®ï¼Œå°è¯•å¯¼å…¥é…ç½®è§£æåº“
    if [ -f "$(dirname "${BASH_SOURCE[0]}")/config_resolver.sh" ]; then
        source "$(dirname "${BASH_SOURCE[0]}")/config_resolver.sh"
        WIKI_CONFIG=$(find_config_file)
    fi

    # å¦‚æœä»ç„¶æœªæ‰¾åˆ°ï¼ŒæŠ¥é”™
    if [ -z "$WIKI_CONFIG" ]; then
        echo "âŒ é”™è¯¯: WIKI_CONFIG ç¯å¢ƒå˜é‡æœªè®¾ç½®" >&2
        echo "ğŸ’¡ æç¤º: è¯·å…ˆè¿è¡Œé…ç½®åˆå§‹åŒ–æµç¨‹" >&2
        return 1
    fi

    export WIKI_CONFIG
fi

# è·å–å…ƒæ•°æ®æ–‡ä»¶è·¯å¾„ï¼ˆæ ¹æ®é…ç½®ï¼‰
# å…ƒæ•°æ®æ–‡ä»¶å­˜å‚¨åœ¨ç”¨æˆ·é…ç½®çš„ output_dir ä¸‹çš„ .wiki-metadata/ å­ç›®å½•
get_metadata_file() {
    local config_file="$WIKI_CONFIG"

    # è¯»å– output_dir é…ç½®
    local output_dir=$(python3 - <<PYTHON_EOF
import json
from pathlib import Path

config_path = Path("$config_file")
if config_path.exists():
    with open(config_path, 'r', encoding='utf-8') as f:
        config = json.load(f)
        print(config.get('output_dir', 'docs'))
else:
    print('docs')
PYTHON_EOF
)

    # å…ƒæ•°æ®æ–‡ä»¶æ”¾åœ¨è¾“å‡ºç›®å½•çš„ .wiki-metadata/ å­ç›®å½•
    echo "$output_dir/.wiki-metadata/metadata.json"
}

# åˆå§‹åŒ–å…ƒæ•°æ®æ–‡ä»¶
init_metadata() {
    local metadata_file=$(get_metadata_file)
    local metadata_dir=$(dirname "$metadata_file")

    # åˆ›å»ºç›®å½•
    mkdir -p "$metadata_dir"

    if [ ! -f "$metadata_file" ]; then
        cat > "$metadata_file" <<'EOF'
{
  "version": "3.1.0",
  "last_generation": {
    "commit": "",
    "timestamp": ""
  },
  "document_mappings": {}
}
EOF
        echo "âœ… å·²åˆå§‹åŒ–å…ƒæ•°æ®æ–‡ä»¶: $metadata_file"
    fi
}

# è®°å½•æ–‡æ¡£ç”Ÿæˆä¿¡æ¯
# ç”¨æ³•: record_document <doc_name> <source_files_json> <commit_hash>
record_document() {
    local doc_name=$1
    local source_files=$2  # JSON æ•°ç»„å­—ç¬¦ä¸²
    local commit_hash=$3
    local metadata_file=$(get_metadata_file)

    # ä½¿ç”¨å†…è” Python è®¡ç®—å“ˆå¸Œå¹¶æ›´æ–° JSON
    python3 - <<PYTHON_EOF
import json
import hashlib
from pathlib import Path
from datetime import datetime

metadata_file = Path("$metadata_file")
doc_name = "$doc_name"
source_files = json.loads("""$source_files""")
commit_hash = "$commit_hash"

# åŠ è½½å…ƒæ•°æ®
with open(metadata_file, 'r', encoding='utf-8') as f:
    metadata = json.load(f)

# è®¡ç®—æ–‡ä»¶å“ˆå¸Œ
file_hashes = {}
for file_path in source_files:
    if Path(file_path).exists():
        try:
            with open(file_path, 'rb') as f:
                # åªè®¡ç®—å®è´¨æ€§å†…å®¹ï¼ˆæ’é™¤ç©ºè¡Œå’Œæ³¨é‡Šï¼‰
                content = f.read().decode('utf-8', errors='ignore')
                lines = [l for l in content.split('\n')
                        if l.strip() and not l.strip().startswith('#')]
                content_hash = hashlib.sha256('\n'.join(lines).encode()).hexdigest()
                file_hashes[file_path] = content_hash
        except Exception as e:
            print(f"âš ï¸  æ— æ³•è¯»å–æ–‡ä»¶ {file_path}: {e}", file=__stderr__)

# è®°å½•æ–‡æ¡£ä¿¡æ¯
metadata['document_mappings'][doc_name] = {
    'source_files': source_files,
    'hashes': file_hashes,
    'generated_at': datetime.utcnow().isoformat() + 'Z',
    'commit': commit_hash
}

# ä¿å­˜å…ƒæ•°æ®
with open(metadata_file, 'w', encoding='utf-8') as f:
    json.dump(metadata, f, indent=2, ensure_ascii=False)

print(f"âœ… å·²è®°å½•æ–‡æ¡£å…ƒæ•°æ®: {doc_name}", file=__stderr__)
PYTHON_EOF
}

# æ£€æŸ¥æ–‡æ¡£æ˜¯å¦éœ€è¦æ›´æ–°
# ç”¨æ³•: needs_update <doc_name>
# è¾“å‡º: "UPDATE_NEEDED" | "NO_UPDATE" | "NEW_DOCUMENT" | "ERROR: ..."
needs_update() {
    local doc_name=$1
    local metadata_file=$(get_metadata_file)

    # æ£€æŸ¥å…ƒæ•°æ®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if [ ! -f "$metadata_file" ]; then
        echo "NEW_DOCUMENT"
        return 0
    fi

    # ä½¿ç”¨å†…è” Python æ£€æŸ¥
    local result=$(python3 - <<PYTHON_EOF
import json
import hashlib
from pathlib import Path

metadata_file = Path("$metadata_file")
doc_name = "$doc_name"

try:
    with open(metadata_file, 'r', encoding='utf-8') as f:
        metadata = json.load(f)

    doc_info = metadata['document_mappings'].get(doc_name)
    if not doc_info:
        print("NEW_DOCUMENT")
        exit(0)

    # æ£€æŸ¥æ–‡ä»¶å“ˆå¸Œ
    stored_hashes = doc_info.get('hashes', {})
    for file_path, stored_hash in stored_hashes.items():
        if Path(file_path).exists():
            try:
                with open(file_path, 'rb') as f:
                    content = f.read().decode('utf-8', errors='ignore')
                    lines = [l for l in content.split('\n')
                            if l.strip() and not l.strip().startswith('#')]
                    current_hash = hashlib.sha256('\n'.join(lines).encode()).hexdigest()

                    if current_hash != stored_hash:
                        print(f"UPDATE_NEEDED ({file_path})")
                        exit(0)
            except Exception:
                # æ–‡ä»¶è¯»å–å¤±è´¥ï¼Œè§†ä¸ºéœ€è¦æ›´æ–°
                print(f"UPDATE_NEEDED (error reading {file_path})")
                exit(0)
        else:
            # æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè§†ä¸ºéœ€è¦æ›´æ–°
            print(f"UPDATE_NEEDED ({file_path} not found)")
            exit(0)

    print("NO_UPDATE")
except Exception as e:
    print(f"ERROR: {e}")
PYTHON_EOF
)

    echo "$result"
}

# æ›´æ–°å…¨å±€ç”Ÿæˆä¿¡æ¯
# ç”¨æ³•: update_global_metadata <commit_hash>
update_global_metadata() {
    local commit_hash=$1
    local timestamp=$(date -u +%Y-%m-%dT%H:%M:%SZ)
    local metadata_file=$(get_metadata_file)

    python3 - <<PYTHON_EOF
import json
from pathlib import Path

metadata_file = Path("$metadata_file")

# ç¡®ä¿æ–‡ä»¶å­˜åœ¨
if not metadata_file.exists():
    metadata_file.parent.mkdir(parents=True, exist_ok=True)
    with open(metadata_file, 'w') as f:
        json.dump({
            "version": "3.1.0",
            "last_generation": {"commit": "", "timestamp": ""},
            "document_mappings": {}
        }, f)

with open(metadata_file, 'r', encoding='utf-8') as f:
    metadata = json.load(f)

metadata['last_generation']['commit'] = "$commit_hash"
metadata['last_generation']['timestamp'] = "$timestamp"

with open(metadata_file, 'w', encoding='utf-8') as f:
    json.dump(metadata, f, indent=2, ensure_ascii=False)
PYTHON_EOF

    echo "âœ… å·²æ›´æ–°å…¨å±€å…ƒæ•°æ® (commit: $commit_hash)"
}

# è·å–ä¸Šæ¬¡ç”Ÿæˆçš„ commit hash
# ç”¨æ³•: get_last_commit
get_last_commit() {
    local metadata_file=$(get_metadata_file)

    if [ ! -f "$metadata_file" ]; then
        echo ""
        return 1
    fi

    python3 - <<PYTHON_EOF
import json
from pathlib import Path

metadata_file = Path("$metadata_file")
try:
    with open(metadata_file, 'r', encoding='utf-8') as f:
        metadata = json.load(f)
        print(metadata.get('last_generation', {}).get('commit', ''))
except:
    print('')
PYTHON_EOF
}

# è·å–æ–‡æ¡£å…³è”çš„æºæ–‡ä»¶åˆ—è¡¨
# ç”¨æ³•: get_document_sources <doc_name>
get_document_sources() {
    local doc_name=$1
    local metadata_file=$(get_metadata_file)

    if [ ! -f "$metadata_file" ]; then
        echo "[]"
        return 1
    fi

    python3 - <<PYTHON_EOF
import json
from pathlib import Path

metadata_file = Path("$metadata_file")
doc_name = "$doc_name"

try:
    with open(metadata_file, 'r', encoding='utf-8') as f:
        metadata = json.load(f)
        doc_info = metadata['document_mappings'].get(doc_name, {})
        sources = doc_info.get('source_files', [])
        print(json.dumps(sources))
except:
    print('[]')
PYTHON_EOF
}

# åˆ—å‡ºæ‰€æœ‰å·²è®°å½•çš„æ–‡æ¡£
# ç”¨æ³•: list_documents
list_documents() {
    local metadata_file=$(get_metadata_file)

    if [ ! -f "$metadata_file" ]; then
        echo "âš ï¸  å…ƒæ•°æ®æ–‡ä»¶ä¸å­˜åœ¨"
        return 1
    fi

    python3 - <<PYTHON_EOF
import json
from pathlib import Path

metadata_file = Path("$metadata_file")

try:
    with open(metadata_file, 'r', encoding='utf-8') as f:
        metadata = json.load(f)
        docs = metadata.get('document_mappings', {}).keys()

        if docs:
            print("ğŸ“š å·²è®°å½•çš„æ–‡æ¡£:")
            for doc in sorted(docs):
                print(f"  - {doc}")
        else:
            print("ğŸ“­ æš‚æ— å·²è®°å½•çš„æ–‡æ¡£")
except Exception as e:
    print(f"âŒ è¯»å–å¤±è´¥: {e}")
PYTHON_EOF
}

# æ¸…ç†æ–‡æ¡£å…ƒæ•°æ®
# ç”¨æ³•: remove_document <doc_name>
remove_document() {
    local doc_name=$1
    local metadata_file=$(get_metadata_file)

    if [ ! -f "$metadata_file" ]; then
        echo "âš ï¸  å…ƒæ•°æ®æ–‡ä»¶ä¸å­˜åœ¨"
        return 1
    fi

    python3 - <<PYTHON_EOF
import json
from pathlib import Path

metadata_file = Path("$metadata_file")
doc_name = "$doc_name"

try:
    with open(metadata_file, 'r', encoding='utf-8') as f:
        metadata = json.load(f)

    if doc_name in metadata.get('document_mappings', {}):
        del metadata['document_mappings'][doc_name]

        with open(metadata_file, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, indent=2, ensure_ascii=False)

        print(f"âœ… å·²åˆ é™¤æ–‡æ¡£å…ƒæ•°æ®: {doc_name}")
    else:
        print(f"âš ï¸  æ–‡æ¡£ä¸å­˜åœ¨: {doc_name}")
except Exception as e:
    print(f"âŒ åˆ é™¤å¤±è´¥: {e}")
PYTHON_EOF
}

# å¤‡ä»½å…ƒæ•°æ®æ–‡ä»¶
# ç”¨æ³•: backup_metadata
backup_metadata() {
    local metadata_file=$(get_metadata_file)

    if [ ! -f "$metadata_file" ]; then
        echo "âš ï¸  å…ƒæ•°æ®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œæ— éœ€å¤‡ä»½"
        return 1
    fi

    local backup_dir="${metadata_file}.backup"
    local timestamp=$(date +%Y%m%d_%H%M%S)
    local backup_file="${backup_dir}/metadata_${timestamp}.json"

    mkdir -p "$backup_dir"
    cp "$metadata_file" "$backup_file"

    echo "âœ… å…ƒæ•°æ®å·²å¤‡ä»½åˆ°: $backup_file"
}

# æ¢å¤å…ƒæ•°æ®æ–‡ä»¶
# ç”¨æ³•: restore_metadata <backup_file>
restore_metadata() {
    local backup_file=$1
    local metadata_file=$(get_metadata_file)

    if [ ! -f "$backup_file" ]; then
        echo "âŒ å¤‡ä»½æ–‡ä»¶ä¸å­˜åœ¨: $backup_file"
        return 1
    fi

    cp "$backup_file" "$metadata_file"
    echo "âœ… å…ƒæ•°æ®å·²ä»å¤‡ä»½æ¢å¤"
}
