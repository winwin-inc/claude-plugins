# å˜æ›´æ£€æµ‹ Skill

**åŠŸèƒ½**: æ£€æµ‹ä»£ç å˜æ›´å¹¶æ˜ å°„åˆ°å—å½±å“çš„æ–‡æ¡£

**ç‰ˆæœ¬**: 3.1.0

---

## æ¦‚è¿°

å˜æ›´æ£€æµ‹ skill é€šè¿‡ä»¥ä¸‹ä¸‰ç§æ–¹å¼æ£€æµ‹ä»£ç å˜æ›´ï¼š
1. **Git diff åˆ†æ** - æ£€æµ‹è‡ªä¸Šæ¬¡ç”Ÿæˆä»¥æ¥å˜æ›´çš„æ–‡ä»¶
2. **å“ˆå¸Œå€¼æ¯”è¾ƒ** - è¯†åˆ«å®è´¨æ€§å†…å®¹å˜åŒ–ï¼ˆæ’é™¤ç©ºæ ¼ã€æ³¨é‡Šï¼‰
3. **æ¨¡å—ä¾èµ–åˆ†æ** - å»ºç«‹æ–‡æ¡£ä¸æºæ–‡ä»¶çš„æ˜ å°„å…³ç³»

---

## æ ¸å¿ƒå‡½æ•°

### detect_changes()

**åŠŸèƒ½**: æ£€æµ‹ä»£ç å˜æ›´å¹¶è¿”å›å—å½±å“çš„æ–‡æ¡£åˆ—è¡¨

**ç”¨æ³•**:
```bash
detect_changes <project_dir> [base_commit]
```

**å‚æ•°**:
- `project_dir`: é¡¹ç›®æ ¹ç›®å½•
- `base_commit`: å¯é€‰ï¼ŒåŸºå‡† commitï¼ˆé»˜è®¤ï¼šä¸Šæ¬¡ç”Ÿæˆçš„ commitï¼‰

**è¾“å‡º**: JSON æ ¼å¼çš„å˜æ›´ä¿¡æ¯

```bash
#!/usr/bin/env bash
# å˜æ›´æ£€æµ‹ä¸»å‡½æ•°
# ç”¨æ³•: detect_changes <project_dir> [base_commit]

detect_changes() {
    local project_dir=$1
    local base_commit=$2

    # 1. è·å–ä¸Šæ¬¡ç”Ÿæˆçš„ commitï¼ˆå¦‚æœæœªæä¾›ï¼‰
    if [ -z "$base_commit" ]; then
        base_commit=$(get_last_commit)
        if [ -z "$base_commit" ]; then
            # é¦–æ¬¡ç”Ÿæˆï¼Œä½¿ç”¨å½“å‰ commit çš„çˆ¶æäº¤
            base_commit=$(git -C "$project_dir" rev-parse HEAD^ 2>/dev/null || echo "")
        fi
    fi

    local current_commit=$(git -C "$project_dir" rev-parse HEAD)

    # å¦‚æœæ²¡æœ‰åŸºå‡† commitï¼Œè§†ä¸ºé¦–æ¬¡ç”Ÿæˆ
    if [ -z "$base_commit" ]; then
        cat <<EOF
{
  "base_commit": "",
  "current_commit": "$current_commit",
  "is_initial": true,
  "changed_files": [],
  "affected_documents": "all",
  "deleted_files": []
}
EOF
        return 0
    fi

    # 2. Git diff åˆ†æ
    local changed_files=$(git -C "$project_dir" diff --name-only "$base_commit" "$current_commit" 2>/dev/null)

    # 3. è¿‡æ»¤æºä»£ç æ–‡ä»¶
    local source_files=$(filter_source_files "$changed_files")

    # 4. è®¡ç®—å“ˆå¸Œå€¼
    local hashes_json=$(calculate_batch_hashes_json "$source_files")

    # 5. æ˜ å°„åˆ°å—å½±å“çš„æ–‡æ¡£
    local affected_docs=$(map_to_documents "$source_files" "$project_dir")

    # 6. è¾“å‡º JSON ç»“æœ
    cat <<EOF
{
  "base_commit": "$base_commit",
  "current_commit": "$current_commit",
  "is_initial": false,
  "changed_files": $(echo "$source_files" | jq -R -s -c 'split("\n")[:-1]'),
  "file_hashes": $hashes_json,
  "affected_documents": $affected_docs,
  "deleted_files": []
}
EOF
}
```

---

## è¾…åŠ©å‡½æ•°

### filter_source_files()

**åŠŸèƒ½**: è¿‡æ»¤åªåŒ…å«æºä»£ç æ–‡ä»¶ï¼ˆæ’é™¤æµ‹è¯•ã€mocks ç­‰ï¼‰

```bash
#!/usr/bin/env bash
# è¿‡æ»¤æºä»£ç æ–‡ä»¶
# ç”¨æ³•: filter_source_files <file_list>
# æ³¨æ„: WIKI_CONFIG ç¯å¢ƒå˜é‡ç”±è°ƒç”¨æ–¹è®¾ç½®ï¼ˆé€šè¿‡ config_resolver.shï¼‰

filter_source_files() {
    local file_list=$1

    # ä»é…ç½®è¯»å–æ’é™¤æ¨¡å¼
    # WIKI_CONFIG ç¯å¢ƒå˜é‡ç”± config_resolver.sh ç®¡ç†
    # é…ç½®æ–‡ä»¶ä½ç½®: {output_dir}/wiki-config.json
    local exclude_patterns=$(python3 - <<PYTHON_EOF
import json
from pathlib import Path

config_path = Path("$WIKI_CONFIG")
if config_path.exists():
    with open(config_path, 'r', encoding='utf-8') as f:
        config = json.load(f)
        patterns = config.get('change_detection', {}).get('exclude_patterns', [])
        print('|'.join(patterns))
else:
    print('tests/**|*.test.*|mocks/**')
PYTHON_EOF
)

    # è¿‡æ»¤æ–‡ä»¶
    echo "$file_list" | grep -E '\.(py|js|ts|tsx|jsx|go|java|rs|rb|php|cs|swift|kt)$' | \
        grep -v -E '(test_|_test\.|\.test\.)' | \
        grep -v -E "$exclude_patterns" || true
}
```

### calculate_batch_hashes_json()

**åŠŸèƒ½**: æ‰¹é‡è®¡ç®—æ–‡ä»¶å“ˆå¸Œå€¼

```bash
#!/usr/bin/env bash
# æ‰¹é‡è®¡ç®—æ–‡ä»¶å“ˆå¸Œ
# ç”¨æ³•: calculate_batch_hashes_json <file_list>

calculate_batch_hashes_json() {
    local file_list=$1

    # è½¬æ¢ä¸º JSON æ•°ç»„
    local files_json=$(echo "$file_list" | jq -R -s -c 'split("\n")[:-1]')

    # ä½¿ç”¨å†…è” Python è®¡ç®—å“ˆå¸Œ
    python3 <<PYTHON_EOF
import json
import hashlib
from pathlib import Path

files = json.loads('''$files_json''')
hashes = {}

for file_path in files:
    if Path(file_path).exists():
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                # æå–å®è´¨æ€§å†…å®¹ï¼ˆæ’é™¤ç©ºè¡Œå’Œæ³¨é‡Šï¼‰
                lines = [l.strip() for l in f
                        if l.strip() and not l.strip().startswith('#')]
                content = '\n'.join(lines)
                hashes[file_path] = hashlib.sha256(content.encode()).hexdigest()
        except Exception as e:
            hashes[file_path] = None
    else:
        hashes[file_path] = None

print(json.dumps(hashes, indent=2))
PYTHON_EOF
}
```

### map_to_documents()

**åŠŸèƒ½**: å°†å˜æ›´æ–‡ä»¶æ˜ å°„åˆ°å—å½±å“çš„æ–‡æ¡£

```bash
#!/usr/bin/env bash
# æ˜ å°„æ–‡ä»¶åˆ°æ–‡æ¡£
# ç”¨æ³•: map_to_documents <file_list> <project_dir>

map_to_documents() {
    local file_list=$1
    local project_dir=$2

    # ä½¿ç”¨å†…è” Python æ‰§è¡Œæ˜ å°„
    python3 <<PYTHON_EOF
import json
from pathlib import Path
import re

files_str = """$file_list"""
changed_files = [f for f in files_str.split('\n') if f.strip()]

# æ–‡æ¡£åˆ°æºæ–‡ä»¶çš„æ˜ å°„è§„åˆ™
document_mappings = {
    'quickstart': ['README.md', 'README.txt', 'README', 'package.json', 'pyproject.toml', 'setup.py', 'pom.xml', 'build.gradle'],
    'overview': ['README.md', 'CONTRIBUTING.md', 'docs/*.md'],
    'techstack': ['package.json', 'requirements.txt', 'pyproject.toml', 'go.mod', 'Cargo.toml', 'pom.xml', 'Gemfile'],
    'architecture': ['src/**/*.py', 'src/**/*.js', 'src/**/*.ts', 'app/**/*.py', 'lib/**/*.py'],
    'datamodel': ['**/models/**/*.py', '**/model/**/*.py', '**/entities/**/*.py', '**/schemas/**/*.py'],
    'api': ['**/api/**/*.py', '**/routes/**/*.py', '**/controllers/**/*.py', '**/handlers/**/*.py'],
    'corefeatures': ['src/**/*.py', 'app/**/*.py', 'lib/**/*.py'],
    'deployment': ['Dockerfile', 'docker-compose.yml', 'k8s/**/*.yaml', '*.deploy.yml', 'deployment/*.yml'],
    'testing': ['tests/**/*.py', 'test/**/*.py', '**/*_test.py', '**/test_*.py'],
    'security': ['**/auth/**/*.py', '**/security/**/*.py', '**/middleware/**/*.py']
}

# æ‰¾å‡ºå—å½±å“çš„æ–‡æ¡£
affected_docs = set()

for file_path in changed_files:
    file_name = Path(file_path).name
    file_dir = Path(file_path).parent.as_posix()

    for doc_name, patterns in document_mappings.items():
        for pattern in patterns:
            # ç®€å•æ¨¡å¼åŒ¹é…
            if pattern in file_path:
                affected_docs.add(doc_name)
                break
            # é€šé…ç¬¦åŒ¹é…
            elif '**' in pattern or '*' in pattern:
                # å°† glob æ¨¡å¼è½¬æ¢ä¸ºæ­£åˆ™è¡¨è¾¾å¼
                regex_pattern = pattern.replace('**', '.*').replace('*', '[^/]*')
                if re.search(regex_pattern, file_path) or re.search(regex_pattern, file_dir):
                    affected_docs.add(doc_name)
                    break

if affected_docs:
    print(json.dumps(sorted(affected_docs), indent=2))
else:
    print('[]')
PYTHON_EOF
}
```

---

## ä½¿ç”¨ç¤ºä¾‹

### ç¤ºä¾‹ 1: æ£€æµ‹è‡ªä¸Šæ¬¡ç”Ÿæˆä»¥æ¥çš„å˜æ›´

```bash
# åŠ è½½å…ƒæ•°æ®è¿½è¸ªåº“
source plugins/libs/metadata_tracker.sh

# æ£€æµ‹å˜æ›´
changes=$(detect_changes ".")

# è§£æç»“æœ
base_commit=$(echo "$changes" | jq -r '.base_commit')
affected_docs=$(echo "$changes" | jq -r '.affected_documents')

echo "åŸºå‡† commit: $base_commit"
echo "å—å½±å“çš„æ–‡æ¡£: $affected_docs"
```

### ç¤ºä¾‹ 2: ä¸ç°æœ‰æ–‡æ¡£å¯¹æ¯”

```bash
# æ£€æµ‹å˜æ›´
changes=$(detect_changes ".")

# éå†å—å½±å“çš„æ–‡æ¡£
for doc in $(echo "$changes" | jq -r '.affected_documents[]'); do
    # æ£€æŸ¥æ–‡æ¡£æ˜¯å¦éœ€è¦æ›´æ–°
    update_status=$(needs_update "$doc")

    if [[ "$update_status" == UPDATE_NEEDED* ]]; then
        echo "ğŸ“ æ–‡æ¡£ '$doc' éœ€è¦æ›´æ–°: $update_status"
    fi
done
```

### ç¤ºä¾‹ 3: æ£€æµ‹ç‰¹å®šæ–‡ä»¶å˜æ›´

```bash
# æ£€æµ‹ç‰¹å®šæ–‡ä»¶çš„å˜æ›´
changes=$(detect_changes "." "abc123")

# è·å–å˜æ›´æ–‡ä»¶åˆ—è¡¨
changed_files=$(echo "$changes" | jq -r '.changed_files[]')

for file in $changed_files; do
    echo "ğŸ“„ å˜æ›´æ–‡ä»¶: $file"
done
```

---

## è¾“å‡ºæ ¼å¼

### é¦–æ¬¡ç”Ÿæˆ

```json
{
  "base_commit": "",
  "current_commit": "abc123...",
  "is_initial": true,
  "changed_files": [],
  "affected_documents": "all",
  "deleted_files": []
}
```

### å¢é‡æ›´æ–°

```json
{
  "base_commit": "abc123...",
  "current_commit": "def456...",
  "is_initial": false,
  "changed_files": [
    "src/models/user.py",
    "src/services/user_service.py",
    "api/routes/users.py"
  ],
  "file_hashes": {
    "src/models/user.py": "sha256...",
    "src/services/user_service.py": "sha256...",
    "api/routes/users.py": "sha256..."
  },
  "affected_documents": [
    "datamodel",
    "api",
    "corefeatures"
  ],
  "deleted_files": []
}
```

---

## é…ç½®é€‰é¡¹

### wiki-config.json

```json
{
  "change_detection": {
    "method": "both",  // "git" | "hash" | "both"
    "base_commit": "",  // ç•™ç©ºè‡ªåŠ¨æ£€æµ‹
    "exclude_patterns": [
      "tests/**",
      "*.test.*",
      "mocks/**",
      "**/*.spec.ts",
      "**/*.test.js"
    ]
  }
}
```

---

## æ•…éšœæ’é™¤

### é—®é¢˜ 1: Git ä»“åº“æœªåˆå§‹åŒ–

**é”™è¯¯**: `fatal: not a git repository`

**è§£å†³æ–¹æ¡ˆ**:
```bash
# åœ¨é¡¹ç›®ç›®å½•ä¸­åˆå§‹åŒ– Git ä»“åº“
git init
git add -A
git commit -m "Initial commit"
```

### é—®é¢˜ 2: æ—  commit å†å²

**é”™è¯¯**: `fatal: bad revision 'HEAD^'`

**è§£å†³æ–¹æ¡ˆ**: æ£€æµ‹é¦–æ¬¡ç”Ÿæˆï¼Œè¿”å›æ‰€æœ‰æ–‡æ¡£ï¼š
```bash
if ! git rev-parse HEAD^ >/dev/null 2>&1; then
    echo '{"is_initial": true, "affected_documents": "all"}'
fi
```

### é—®é¢˜ 3: å…ƒæ•°æ®æ–‡ä»¶æŸå

**è§£å†³æ–¹æ¡ˆ**: ä½¿ç”¨å¤‡ä»½æ¢å¤
```bash
# æ¢å¤æœ€è¿‘çš„å¤‡ä»½
restore_metadata "docs/.wiki-metadata/metadata.json.backup/metadata_*.json"
```

---

## æ€§èƒ½ä¼˜åŒ–

### æ‰¹é‡å“ˆå¸Œè®¡ç®—

ä½¿ç”¨å¹¶è¡Œè®¡ç®—åŠ é€Ÿå“ˆå¸Œè®¡ç®—ï¼ˆå¦‚æœæ–‡ä»¶æ•°é‡å¤§ï¼‰:

```bash
# å®‰è£… parallelï¼ˆå¦‚æœæœªå®‰è£…ï¼‰
# sudo apt-get install parallel

# å¹¶è¡Œè®¡ç®—å“ˆå¸Œ
calculate_parallel_hashes() {
    local files=$1

    echo "$files" | parallel -j 4 'calculate_file_hash {}' | \
        paste -sd,
}
```

### ç¼“å­˜æœºåˆ¶

å¯¹äºæœªå˜æ›´çš„æ–‡ä»¶ï¼Œä½¿ç”¨ç¼“å­˜çš„å“ˆå¸Œå€¼ï¼š

```bash
# åœ¨å…ƒæ•°æ®ä¸­å­˜å‚¨å“ˆå¸Œç¼“å­˜
# åªå¯¹å®é™…å˜æ›´çš„æ–‡ä»¶é‡æ–°è®¡ç®—å“ˆå¸Œ
```

---

## é›†æˆç‚¹

### è°ƒç”¨æ–¹: wiki-generate å‘½ä»¤

```markdown
### å¢é‡æ›´æ–°æ¨¡å¼

1. **åŠ è½½å…ƒæ•°æ®**
   ```bash
   source plugins/libs/metadata_tracker.sh
   init_metadata
   ```

2. **å˜æ›´æ£€æµ‹**
   ```bash
   changes=$(detect_changes "$PROJECT_DIR")
   affected_docs=$(echo "$changes" | jq -r '.affected_documents')
   ```

3. **é€‰æ‹©æ€§ç”Ÿæˆ**
   ```bash
   for doc in $affected_docs; do
       if needs_update "$doc" | grep -q "UPDATE_NEEDED"; then
           # ç”Ÿæˆæ–°å†…å®¹
           new_content=$(generate_document "$doc")

           # æ™ºèƒ½åˆå¹¶
           if [ -f "$OUTPUT_DIR/$doc.md" ]; then
               merged=$(smart_merge "$OUTPUT_DIR/$doc.md" "$new_content")
               echo "$merged" > "$OUTPUT_DIR/$doc.md"
           else
               echo "$new_content" > "$OUTPUT_DIR/$doc.md"
           fi
       fi
   done
   ```

4. **æ›´æ–°å…ƒæ•°æ®**
   ```bash
   current_commit=$(git rev-parse HEAD)
   update_global_metadata "$current_commit"
   ```
```

---

**ç‰ˆæœ¬**: 3.1.0
**æœ€åæ›´æ–°**: 2026-01-07
